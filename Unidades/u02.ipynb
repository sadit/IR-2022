{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b606b63e-967d-4d4d-85e4-e02a32020425",
   "metadata": {},
   "source": [
    "# BÃºsqueda de texto completo\n",
    "Autor: Eric S. Tellez <eric.tellez@infotec.mx> <br/>\n",
    "\n",
    "Tal vez la tarea mÃ¡s emblemÃ¡tica de la RecuperaciÃ³n de InformaciÃ³n es la bÃºsqueda de _texto completo_.\n",
    "El problema consiste en dado un corpus grande de documentos, preprocesarlo para crear una estructura de bÃºsqueda que permita resolver consultas de manera eficiente. Una consulta es un texto corto que especÃ­fica lo que se desea encontrar en la colecciÃ³n. En particular, es un ejemplo de lo que se desea. Esto lleva a que la estructura de bÃºsqueda resuelve bÃºsquedas por similitud.\n",
    "\n",
    "La similitud, es entonces un tema central, pero para medirla lo primero es tener una representaciÃ³n de los datos que capture las propiedades deseadas (que serÃ¡n despuÃ©s evaluadas para medir la similitud). La manera mÃ¡s tradicional de hacerlo, es el uso de un modelo basado en bolsa de palabras (BOW). En dicho modelo, el texto es preprocesado, toquenizado y vectorizado.\n",
    "\n",
    "- El preprocesamiento incluye tratamientos tan simples como eliminar sÃ­mbolos no deseados, eliminiaciÃ³n de variantes lÃ©xicas, reducciÃ³n a raÃ­ces o lemas, correcciÃ³n de ortografÃ­a, eliminiaciÃ³n de palabras comunes (stop words). \n",
    "- El toquenizado es el proceso donde el texto es partido, en frases u oraciones, y finalmente en palabras y sÃ­mbolos que son unidades completas. En este punto tambiÃ©n es posible realizar normalizaciones, asÃ­ como tambiÃ©n realizar limpieza basada en estadÃ­sticas de los tÃ©rminos.\n",
    "- El vectorizado utiliza el vocabulario de una colecciÃ³n $\\{t_i\\}$ para generar una matriz de la colecciÃ³n, i.e., un vector por documento.\n",
    "\n",
    "Al proceso de modelar una colecciÃ³n mediante un vocabulario y luego ser capaces de generar una representaciÃ³n manejable por una computadora se le llama _modelo de lenguaje_.\n",
    "\n",
    "## Problema de bÃºsqueda\n",
    "Una vez que se genero el modelo de lenguaje y que fue usado para vectorizar una colecciÃ³n $X$, la idea es ser capaces de resolver consultas $Q$, i.e., encontrar un subconjunto de $X$ que mejor se apegue a una especificaciÃ³n $q \\in Q$. Las consultas deben ser codificadas de la misma forma, para generar un vector con ellas. Entonces el problema se transforma en encontrar los elementos mÃ¡s parecidos, que dada la representaciÃ³n, es conveniente usar el coseno entre vectores:\n",
    "\n",
    "$$ \\cos(u, q) = \\frac{ \\sum_i {u_i \\cdot q_i}}{\\sqrt{\\sum_i u_i^2} \\cdot \\sqrt{\\sum_i q_i^2}} $$\n",
    "\n",
    "AsÃ­ mismo, $d(u, q) = \\arccos(\\cos(u, q))$ serÃ­a el Ã¡ngulo entre ambos vectores, que ademÃ¡s es una mÃ©trica. El problema entonces se transforma en encontrar los vecinos mÃ¡s cercanos en la colecciÃ³n, esto es, si deseamos $k$ resultados de una consulta, estarÃ­amos deseando encontrar aquel subconjunto $knn$ de la colecciÃ³n tal que $\\sum_{v \\in knn} d(v, q)$ sea mÃ­nimo comparado con todo subconjunto de tamaÃ±o $k$ de la colecciÃ³n de documentos.\n",
    "\n",
    "## Velocidad de consultas\n",
    "Para mejorar la soluciÃ³n de consultas, es posible crear una estructura de datos que simplifique el proceso de encontrar el subconjunto $knn$. En este problema, con una representaciÃ³n basada en bolsa de palabras, la estructura mÃ¡s adecuada es el _Ã­ndice invertido.\n",
    "\n",
    "\n",
    "# Ãndice invertido\n",
    "\n",
    "Un Ã­ndice invertido es una representaciÃ³n dispersa de la matriz $W_{m,n}$ formada por $m$ componentes y $n$ documentos, i.e., cada celda $w_{t,i}$ es el peso asignado para el tÃ©rmino $t$ que ocurre en el documento $i$. Por construcciÃ³n, esta matriz tiene una gran cantidad de ceros, por lo que $W$ es altamente dispersa (pocos tÃ©rminos ocurren en un documento).\n",
    "\n",
    "$$ W \\left \\{\n",
    "\\begin{array}{rrrr rrrr rr}\n",
    "                & \\vec x_1& \\vec x_2&       & \\vec x_n \\\\\n",
    "t_1 \\rightarrow & w_{1,1} & w_{1,2} & \\dots & w_{1,n} \\\\\n",
    "t_2 \\rightarrow & w_{2,1} & w_{2,2} &       & w_{2,n} \\\\\n",
    "                & \\vdots  &         & \\ddots&         \\\\\n",
    "t_m \\rightarrow & w_{m,1} & w_{m,2} &       & w_{m,n} \\\\\n",
    "\\end{array}\n",
    "\\right .\n",
    "$$\n",
    "\n",
    "La representaciÃ³n es entonces por fila, a manera de lista de adjacencia; esto es, cada fila $t$ es representada por las tuplas $(i, w_{t,i})$, esto es, un Ã­ndice invertido es la siguiente estructura $W^*$\n",
    "\n",
    "$$ W^* \\left \\{\n",
    "\\begin{array}{rrr}\n",
    "t_1 & \\rightarrow & \\{(i, w_{1, i})\\} \\\\\n",
    "t_2 & \\rightarrow & \\{(i, w_{2, i})\\} \\\\\n",
    "\\vdots & \\vdots   &  \\hfill \\vdots \\hfill \\\\\n",
    "t_m & \\rightarrow & \\{(i, w_{m, i})\\} \\\\\n",
    "\\end{array}\n",
    "\\right .\n",
    "$$\n",
    "\n",
    "la tupla es usada siempre y cuando $w > 0$. Las tuplas suelen ordenarse por su identificador de columna, pero tambiÃ©n puede usarse el peso segÃºn convenga. A las filas suele llamarseles listas de posteo (_posting lists_). Los requerimientos de una matriz densa son altÃ­simos para representaciones de texto de alta dimensiÃ³n, representar las matrices de manera dispersa simplifica el manejo de la memorÃ­a, y como se verÃ¡ a continuaciÃ³n, tambiÃ©n influye enormemente en los tiempos de procesamiento.\n",
    "\n",
    "### BÃºsqueda mediante un Ã­ndice invertido\n",
    "\n",
    "La soluciÃ³n na\\\"ive de una obtener los $k$ documentos mÃ¡s similares es evaluar todos los vectores $\\vec{x}_i$, i.e., columnas de $W$, y determinar aquellos mÃ¡s similares, i.e., minimizar $d(\\vec{x}_i, q)$.\n",
    "\n",
    "El Ã­ndice invertido $W^*$ contiene la informaciÃ³n necesaria para realizar esta operaciÃ³n de manera eficiente. Primeramente, es necesario analizar la expresiÃ³n de $\\cos$. El denominador $\\sqrt{\\sum_i u_i^2} \\cdot \\sqrt{\\sum_i q_i^2}$, en sus partes es estÃ¡tico para cada vector, por lo que se puede preprocesar y no calcular de manera explÃ­cita para cada evaluaciÃ³n de $\\cos$. Con respecto al numerador corresponde al producto punto entre $\\vec{u}$ y $\\vec{q}$, $\\sum_i u_i \\cdot q_i$. Dicho esto, solo es necesario calcular los productos diferentes de cero; asÃ­ pues, la evaluaciÃ³n eficiente de $\\cos$ corresponde con una evaluaciÃ³n eficiente de la intersecciÃ³n de las componentes diferentes de cero. Los algoritmos como SvS, BY o BK, pueden ser de gran ayuda para este cÃ¡lculo. Note que aunque que los pesos con valor cero no se representan en $W^*$, dicho Ã­ndice representa informaciÃ³n por fila, lo cual no permite hacer operaciones eficientes entre $q$ y los vectores columna $\\vec x$ individuales.\n",
    "\n",
    "\n",
    "Afortunadamente, la evaluaciÃ³n se puede hacer eficiente para todo el conjunto de posibles candidatos (aquellos donde el producto punto contra $q$ sea diferente de cero). Para esto, se toman las componentes diferentes de cero en $q$, se toman las listas de adyacencia de $W^*$ y se procede a unirlas de manera eficiente. El conjunto de identificadores de documento resultado de esta uniÃ³n serÃ¡ aquel que debe ser evaluado para obtener el conjunto de documentos similares. \n",
    "Si uno toma la intersecciÃ³n, que puede ser mÃ¡s veloz de calcular, entonces podrÃ­an perderse documentos relavantes; es posible tambiÃ©n mandar el problema a un punto intermedio, es decir al problema de $t$-thresholds, donde se recupera un conjunto donde cada uno de los miembros aparece en al menos $t$ listas.\n",
    "La manera mÃ¡s eficiente, sin embargo, es realizar optimizaciones por filtrado de pesos o mejorando los esquemas de pesado; la idea general entonces es desaparecer entradas de $W*$ de tal forma que la uniÃ³n sea siempre pequeÃ±a. La adecuada optimizaciÃ³n de un Ã­ndice invertido puede hacerlo escalable a niveles realmente impresionantes.\n",
    "\n",
    "Los algoritmos de BK pueden ser utilizados para calcular la uniÃ³n y t-threasholds, asÃ­ como los algoritmos de mezcla clÃ¡sicos (_merge_). Es posible unir la operaciÃ³n de uniÃ³n con la operaciÃ³n de producto punto por vector usando los algoritmos adecuados.\n",
    "\n",
    "- <https://github.com/sadit/InvertedFiles.jl/blob/main/src/invfilesearch.jl>\n",
    "- <https://github.com/sadit/InvertedFiles.jl/blob/main/src/winvfilesearch.jl>\n",
    "- <https://github.com/sadit/Intersections.jl/blob/main/src/merge.jl>\n",
    "\n",
    "# Medidas de calidad (scores)\n",
    "La mediciÃ³n de la calidad en un sistema de bÃºsqueda es fundamental para obtener un sistema de RI adecuado. La idea bÃ¡sica es que un algoritmo recupere la informaciÃ³n adecuada para solventar los requerimientos de las consultas hechas por usuarios. Dicho de otra forma, si se piden $k$ documentos relacionados a una consulta $q$, se medirÃ¡ que porcentaje de esos $k$ son relevantes para el usuario.\n",
    "La evaluaciÃ³n de relevancia de un documento es hecha previamente por _usuarios expertos_ en el dominio del corpus y las consultas. A esta funciÃ³n de relevancia se le llama $\\textsf{recall}$.\n",
    "\n",
    "$$ \\textsf{recall}(\\text{doc. recuperados}, \\text{doc. esperados}) = \\frac{\\left| \\text{doc. recuperados} \\cap \\text{doc esperados} \\right|}{\\left|\\text{doc. esperados}\\right|} $$\n",
    "\n",
    "Note que no se espera precisamente que cada conjunto de resultados sea de tamaÃ±o idÃ©ntico, aunque esta serÃ¡ la norma en nuestro curso. Para obtener una estadÃ­stica fiable, la relevancia serÃ¡ promediada para obtener la calidad del modelo o algoritmo ante un conjunto de consultas. Llamaremos $\\textsf{macrorecall}$ al promedio de los recalls varias consultas.\n",
    "\n",
    "$$ \\textsf{macrorecall}(R, G) = \\frac{1}{|G|} \\sum_i \\textsf{recall}(R_i, G_i)$$\n",
    "\n",
    "El conjunto $R$ es el conjunto de resultados recuperados para un conjunto de consultas, mientras que $G$ es un conjunto especial de resultados que suele llamarse _gold standard_, que serÃ­a esa el conjunto de resultados fiables obtenidos a travÃ©s de la evaluaciÃ³n de expertos humanos.\n",
    "\n",
    "Es costoso y tardado construir un _gold standard_ para una tarea de recuperaciÃ³n de informaciÃ³n, y mÃ¡s aÃºn, para conjuntos de datos grandes. Es por eso que en este curso, evaluaremos la bondad de los modelos usados para la representaciÃ³n de los datos mediante el uso de tareas de clasificaciÃ³n. En ese sentido la relaciÃ³n entre velocidad y calidad que se muestran no deberÃ¡n tomarse mÃ¡s que de manera informativa ya que no puede ligarse a un sistema de bÃºsqueda en grandes colecciones de documentos.\n",
    "\n",
    "En tÃ©rminos de clasificaciÃ³n se usarÃ¡ un modelo basado en vecinos cercanos ya que son naturalmente implementados con las mÃ¡quinas de bÃºsqueda. Pero se aconseja el uso de otros clasificadores en tareas de clasificaciÃ³n.\n",
    "\n",
    "A lo largo del resto del curso, siempre que sea fÃ¡cil se utilizarÃ¡n particiones separadas entre entramiento y prueba. Como no es nuestro objetivo la clasificaciÃ³n efectiva, si no hay particiones dedicadas, se utilizarÃ¡ una muestra aleatoria del corpus, lo cual puede introducir prejuicios sobre los resultados. Nuestro objetivo es medir la diferencia entre modelos de bÃºsqueda, y deberÃ­a ser suficiente con los resultados que se obtendrÃ¡n, a sabiendas que para tareas de clasificaciÃ³n no aplicarÃ¡ esta metodologÃ­a.\n",
    "\n",
    "### ClasificaciÃ³n de texto\n",
    "La clasificaciÃ³n de texto es una tarea de recuperaciÃ³n de informaciÃ³n que serÃ¡ solo tocada ligeramente en este curso, ya que esta fuera del alcance del mismo. Sin embargo, se usarÃ¡ en una de sus formas mÃ¡s sencillas para evaluaciÃ³n de la calidad de los modelos, como ya se menciono. El problema de clasificaciÃ³n consiste en aprender una funciÃ³n $\\phi(texto) \\rightarrow etiqueta$ apartir de un conjunto de un corpus etiquetado tal que para cada texto $t_i$ en el corpus, existe una $y_i$ que es la etiqueta de $t_i$, de tal forma que al usar un texto nunca antes visto $\\phi(texto')$ la funciÃ³n sea capaz de calcular una etiqueta. La funciÃ³n $\\phi$ basada en recuperar los $k$ vecinos cercanos ($knn$) sobre el corpus de entrenamiento y resolver con la etiqueta mÃ¡s popular entre los $knn$.\n",
    "\n",
    "Hay diferentes tipos de _scores_ que se utilizan, entre ellos el _accuracy_, _precision_, y _recall_, que es un simil de nuestra funciÃ³n de recall. TambiÃ©n se suele tener en cuenta combinaciones de estos como _score_ $F_1$, que es la media armÃ³nica entre _precision_ y _recall_. Las funciones de _accuracy_, _precision_ y _recall_ se definen con respecto al nÃºmero de clases (diferentes etiquetas consideradas) y las funciones bÃ¡sicas TP (true positives), TN (true negatives), FP (false positives), FN (false negatives) <https://en.wikipedia.org/wiki/Precision_and_recall>. Dichas funciones son bien conocidas y usaremos las funciones implementadas en paquetes dedicados enfocando en nuestro objetivo de uso de la bÃºsqueda para medir la calidad de un modelo.\n",
    "\n",
    "\n",
    "## Modelos que toman en cuenta a los usuarios de manera personalizada\n",
    "Los requerimientos entre usuarios podrÃ­an asumirse diferentes, en ese caso, el problema cambiarÃ¡ su forma precisa ya que ahora se deberÃ¡ cumplir que el resultado de una consulta sea relevante para un usuario especÃ­fico, que deberÃ¡ ser modelado de alguna manera para poder generalizarlo. Esta consideraciÃ³n esta fuera del alcance de este curso.\n",
    "\n",
    "# Ejemplo\n",
    "\n",
    "El siguiente es un ejemplo de como cambia el desempeÃ±o usando una evaluaciÃ³n exhaustiva, un Ã­ndice invertido y una pequeÃ±a optimizaciÃ³n basada en modificaciÃ³n de pesos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb11ca12-b635-45bb-ac02-14523674ded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/IR-2022/Unidades`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "\n",
    "!isfile(\"Manifest.toml\") && Pkg.add([\n",
    "    PackageSpec(name=\"SimilaritySearch\", version=\"0.9\"),\n",
    "    PackageSpec(name=\"TextSearch\", version=\"0.12\"),\n",
    "    PackageSpec(name=\"KNearestCenters\", version=\"0.7\"),\n",
    "    PackageSpec(name=\"InvertedFiles\", version=\"0.4\"),\n",
    "    PackageSpec(name=\"CodecZlib\", version=\"0.7\"),\n",
    "    PackageSpec(name=\"JSON\", version=\"0.21\"),\n",
    "    PackageSpec(name=\"HypertextLiteral\", version=\"0.9\")\n",
    "])\n",
    "\n",
    "using TextSearch, InvertedFiles, SimilaritySearch, KNearestCenters, TextSearch, CodecZlib, StatsBase, JSON, LinearAlgebra, HypertextLiteral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae53fa62-8909-4249-9103-6a54232c183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m `~/IR-2022/Unidades/Project.toml`\n",
      " \u001b[90m [944b1d66] \u001b[39mCodecZlib v0.7.0\n",
      " \u001b[90m [ac1192a8] \u001b[39mHypertextLiteral v0.9.4\n",
      " \u001b[90m [b20bd276] \u001b[39mInvertedFiles v0.4.1 `../../Research/InvertedFiles.jl`\n",
      " \u001b[90m [682c06a0] \u001b[39mJSON v0.21.3\n",
      " \u001b[90m [4dca28ae] \u001b[39mKNearestCenters v0.7.1\n",
      " \u001b[90m [8ef0a80b] \u001b[39mLanguages v0.4.3\n",
      " \u001b[90m [eb30cadb] \u001b[39mMLDatasets v0.7.3\n",
      " \u001b[90m [053f045d] \u001b[39mSimilaritySearch v0.9.4 `../../Research/SimilaritySearch.jl`\n",
      " \u001b[90m [fb8f903a] \u001b[39mSnowball v0.1.0\n",
      " \u001b[90m [2913bbd2] \u001b[39mStatsBase v0.33.18\n",
      " \u001b[90m [7f6f6c8a] \u001b[39mTextSearch v0.12.5 `../../Research/TextSearch.jl`\n"
     ]
    }
   ],
   "source": [
    "]status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e9eb5-584e-4cda-8794-b2858c3804c7",
   "metadata": {},
   "source": [
    "### FunciÃ³n de clasificaciÃ³n para medir calidad de un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a515900-5a0a-4114-995f-9eb3157985d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scores (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function knn(index, labels, q, k)\n",
    "    res = KnnResult(k)\n",
    "    search(index, q, res)\n",
    "    mode(labels[idview(res)])\n",
    "end\n",
    "\n",
    "function mymode(c, labels, f)\n",
    "    n = length(c)\n",
    "    empty!(f)\n",
    "    for id in c\n",
    "        id == 0 && break  # searchbatch stores zeros at the end of the result when the result set is smaller than the required one\n",
    "        l = labels[id]\n",
    "        f[l] = get(f, l, 0) + 1\n",
    "    end\n",
    "    \n",
    "    if length(f) == 0\n",
    "        rand(labels)\n",
    "    else\n",
    "        argmax(last, f) |> first\n",
    "    end\n",
    "end\n",
    "\n",
    "function knn(I, labels)\n",
    "    f = Dict{eltype(labels), Int}()\n",
    "    [mymode(c, labels, f) for c in eachcol(I)]\n",
    "end\n",
    "\n",
    "function scores(gold, pred)\n",
    "    s = classification_scores(gold, pred)\n",
    "    (macrof1=s.macrof1, macrorecall=s.macrorecall, accuracy=s.accuracy)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd994e-6be8-45c8-a0fc-8f05dfcf2636",
   "metadata": {},
   "source": [
    "## Funciones para leer y modelar el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9482f05-8d88-4896-9b9e-646bc1da2abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_dataset (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function parse_corpus(corpusfile)\n",
    "    corpus, labels = String[], String[]\n",
    "    open(corpusfile) do f\n",
    "        for line in eachline(GzipDecompressorStream(f))\n",
    "            r = JSON.parse(line)\n",
    "            push!(labels, r[\"klass\"])\n",
    "            push!(corpus, r[\"text\"])    \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    corpus, labels\n",
    "end\n",
    "\n",
    "function text_model_and_vectors(\n",
    "        corpus;\n",
    "        textconfig=TextConfig(group_usr=true, group_url=true, del_diac=true, lc=true, group_num=true, nlist=[1], qlist=[]),\n",
    "        model=VectorModel(IdfWeighting(), TfWeighting(), textconfig, corpus)\n",
    "    )\n",
    "    vectors = vectorize_corpus(model, textconfig, corpus)\n",
    "    for v in vectors\n",
    "        normalize!(v)\n",
    "    end\n",
    "\n",
    "    (; textconfig, model, vectors)\n",
    "end\n",
    "\n",
    "function create_dataset(corpusfile)\n",
    "    corpus, labels = parse_corpus(corpusfile)\n",
    "    (; labels, corpus, text_model_and_vectors(corpus)...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1176ef00-1153-4cba-bb89-354d634c857e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Cargando el corpus (descargado en U1.ipynb)</h1>"
      ],
      "text/plain": [
       "<h1>Cargando el corpus (descargado en U1.ipynb)</h1>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(unique(D.labels), D.model) = ([\"ğŸ˜°\", \"ğŸ˜¥\", \"ğŸ˜Š\", \"ğŸ˜\", \"â™¡\", \"ğŸ’”\", \"ğŸ™‚\", \"ğŸ˜‹\", \"ğŸ˜Œ\", \"ğŸŒš\", \"ğŸ‘Œ\", \"ğŸ˜ª\", \"ğŸ˜¤\", \"ğŸ™ƒ\", \"ğŸ¤¤\", \"ğŸ˜´\", \"ğŸ˜¢\", \"ğŸ˜…\", \"ğŸ˜‘\", \"ğŸ˜ \", \"ğŸ˜‚\", \"ğŸ˜œ\", \"ğŸ¤“\", \"ğŸ’™\", \"ğŸ˜€\", \"ğŸ¤—\", \"ğŸ¤£\", \"ğŸ˜’\", \"âœ¨\", \"ğŸ˜\", \"ğŸ˜\", \"ğŸ˜\", \"ğŸ˜±\", \"ğŸ‘\", \"ğŸ˜«\", \"ğŸ˜\", \"â¤\", \"ğŸ˜£\", \"ğŸ™Š\", \"ğŸ™\", \"ğŸ™„\", \"ğŸ¤­\", \"ğŸ’œ\", \"ğŸ¤”\", \"ğŸ˜¬\", \"ğŸ‘€\", \"ğŸ˜‰\", \"ğŸ˜ˆ\", \"ğŸ˜¡\", \"ğŸ˜³\", \"ğŸ™ˆ\", \"ğŸ˜»\", \"ğŸ˜”\", \"ğŸ˜“\", \"ğŸ’•\", \"ğŸ¶\", \"ğŸ˜­\", \"ğŸ˜•\", \"â™¥\", \"ğŸ’–\", \"ğŸ˜\", \"ğŸ˜˜\", \"ğŸ˜ƒ\", \"ğŸ˜©\"], {VectorModel global_weighting=IdfWeighting(), local_weighting=TfWeighting(), train-voc=45374, train-n=50000, maxoccs=93991})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([\"ğŸ˜°\", \"ğŸ˜¥\", \"ğŸ˜Š\", \"ğŸ˜\", \"â™¡\", \"ğŸ’”\", \"ğŸ™‚\", \"ğŸ˜‹\", \"ğŸ˜Œ\", \"ğŸŒš\"  â€¦  \"ğŸ’•\", \"ğŸ¶\", \"ğŸ˜­\", \"ğŸ˜•\", \"â™¥\", \"ğŸ’–\", \"ğŸ˜\", \"ğŸ˜˜\", \"ğŸ˜ƒ\", \"ğŸ˜©\"], {VectorModel global_weighting=IdfWeighting(), local_weighting=TfWeighting(), train-voc=45374, train-n=50000, maxoccs=93991})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(@htl \"<h1>Cargando el corpus (descargado en U1.ipynb)</h1>\")\n",
    "dbfile = \"../data/emo50k.json.gz\"\n",
    "D = create_dataset(dbfile)\n",
    "@show unique(D.labels), D.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8671092-ee09-4370-b732-4d40d3d4b7b1",
   "metadata": {},
   "source": [
    "# Creando los diferentes mÃ©todos de bÃºsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7ccd91-c1c2-4a04-b792-d38a8c65342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{WeightedInvertedFile vocsize=5408, n=50000}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ã­ndice invertido\n",
    "invfile = WeightedInvertedFile(length(D.model.voc))\n",
    "append!(invfile, VectorDatabase(D.vectors))\n",
    "\n",
    "## indice invertido con filtros al vocabulario\n",
    "fmodel = filter_tokens(D.model) do t\n",
    "    7 <= t.ndocs <= 1000  # filtrando los tokens que ocurren en entre 7 y 1000 documentos\n",
    "end\n",
    "\n",
    "## usando el modelo reducido de tokens\n",
    "fD = text_model_and_vectors(D.corpus, textconfig=D.textconfig, model=fmodel)\n",
    "\n",
    "finvfile = WeightedInvertedFile(length(fD.model.voc))\n",
    "append!(finvfile, VectorDatabase(fD.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d118cb7-f81d-4ad1-80fd-4a5245098ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The token filters can operate on any valid field of voc (passed as the named tuple <em>t</em>)"
      ],
      "text/plain": [
       "The token filters can operate on any valid field of voc (passed as the named tuple <em>t</em>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary <: Any\n",
      "  token::Vector{String}\n",
      "  occs::Vector{Int32}\n",
      "  ndocs::Vector{Int32}\n",
      "  weight::Vector{Float32}\n",
      "  token2id::Dict{String, UInt32}\n",
      "  corpuslen::Int64\n"
     ]
    }
   ],
   "source": [
    "display(@htl \"The token filters can operate on any valid field of voc (passed as the named tuple <em>t</em>)\")\n",
    "\n",
    "dump(typeof(D.model.voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "046760fa-03d2-4bc9-a6cd-418c4f655b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Vector{Int64}, VectorDatabase{Vector{Dict{UInt32, Float32}}}, (992,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qi = unique(rand(1:length(D.vectors), 1000))\n",
    "Qlabels = D.labels[Qi]\n",
    "Q = VectorDatabase(D.vectors[Qi])\n",
    "fQ = VectorDatabase(fD.vectors[Qi]) # son espacios diferentes al ser generados por modelos diferentes\n",
    "typeof(Qi), typeof(Q), size(Qi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f207f2-ed09-4fec-9da6-2ad625c21801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluaciÃ³n exhaustiva\n",
    "brute = ExhaustiveSearch(; db=D.vectors, dist=NormalizedCosineDistance())\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad823b-70c0-447d-bfe0-8a920525ca12",
   "metadata": {},
   "source": [
    "## La siguiente celda se debe correr 2 veces para remover el costo de compilaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde30ad5-8c2d-4622-b0c2-994802b64e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.074409 seconds (2.15 M allocations: 153.711 MiB, 84.38% compilation time)\n",
      "  0.740200 seconds (525.27 k allocations: 27.616 MiB, 33.43% compilation time)\n",
      "  0.014803 seconds (8 allocations: 54.562 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC.enable(false)\n",
    "@time I, _ = searchbatch(invfile, Q, 7)\n",
    "@time B, _ = searchbatch(brute, Q, 7)\n",
    "@time fI, _ = searchbatch(finvfile, fQ, 7)\n",
    "GC.enable(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2427f6-9b89-4bae-a2dd-1a3fbe9960ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc566c35-ebb2-4725-a524-a0737319db22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â”Œ Info: (macrof1 = 0.25526458596380447, macrorecall = 0.2839123666820394, accuracy = 0.2903225806451613)\n",
      "â”” @ Main In[11]:5\n",
      "â”Œ Info: (macrof1 = 0.25526458596380447, macrorecall = 0.2839123666820394, accuracy = 0.2903225806451613)\n",
      "â”” @ Main In[11]:6\n",
      "â”Œ Info: (macrof1 = 0.22456100684915367, macrorecall = 0.2459333551419359, accuracy = 0.2530241935483871)\n",
      "â”” @ Main In[11]:7\n"
     ]
    }
   ],
   "source": [
    "# La diferencia de costos puede ser importante\n",
    "# por lo que es tambiÃ©n necesario saber el impacto con respecto a la calidad perdida\n",
    "# Recuerde que esta es una evaluaciÃ³n estocÃ¡stica\n",
    "let \n",
    "    @info scores(Qlabels, knn(B, D.labels))\n",
    "    @info scores(Qlabels, knn(I, D.labels))\n",
    "    @info scores(Qlabels, knn(fI, D.labels))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f23a7-1e9c-4091-a63c-84695e325598",
   "metadata": {},
   "source": [
    "# Sobre los resultados\n",
    "Lo primero que puede observarse en los resultados es que no son tan buenos como podrÃ­a desearse; recuerde que nuestro objetivo esta en la bÃºsqueda. TambiÃ©n se debe tener en cuenta que esta lejos de una soluciÃ³n aleatoria, ya que son 64 etiquetas. Se puede ver como se multiplica la velocidad varias veces con una calidad muy semejante. En lo posterior, veremos como estos nÃºmeros variarÃ¡n usando diferentes tÃ©cnicas.\n",
    "\n",
    "\n",
    "Finalmente, es necesario remarcar que bÃºsqueda el objetivo es dar a los usuarios informaciÃ³n de Ãºtilidad, y esto suele evaluarse con _gold standards_ generados por humanos. La cantidad de informaciÃ³n serÃ¡ mucho mayor que en tareas de clasificaciÃ³n, y muchas veces, la velocidad es primordia, y si los usuarios encuentran de utilidad los resultados se puede decir que el modelo es efectivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5be69f7-5458-4e1c-b0fa-a14ab2600986",
   "metadata": {},
   "source": [
    "# Actividades\n",
    "\n",
    "- Â¿QuÃ© es el recall?\n",
    "- Â¿QuÃ© es macro-recall?\n",
    "- Explique el porque de las mejoras en tiempo. Use anÃ¡lisis de algoritmos para este ejercicio.\n",
    "- Implemente un Ã­ndice invertido que sea capaz de mejorar los tiempos de bÃºsqueda tal y como se muestra en este ejercicio. Para el procesamiento del texto y toquenizado use librerias/paquetes externos.\n",
    "- Reporte mediante un notebook de Jupyter su implementaciÃ³n, use uno de los conjuntos de datos para ejemplificar su uso y medir los desempeÃ±os.\n",
    "\n",
    "# BibliografÃ­a\n",
    "- [SMR2008] SchÃ¼tze, H., Manning, C. D., & Raghavan, P. (2008). Introduction to information retrieval (Vol. 39, pp. 234-65). Cambridge: Cambridge University Press.\n",
    "- [BYN1999] Baeza-Yates, R., & Ribeiro-Neto, B. (1999). Modern information retrieval (Vol. 463). New York: ACM press."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
