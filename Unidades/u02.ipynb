{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b606b63e-967d-4d4d-85e4-e02a32020425",
   "metadata": {},
   "source": [
    "# BÃºsqueda de texto completo\n",
    "Autor: Eric S. Tellez <eric.tellez@infotec.mx> <br/>\n",
    "\n",
    "Tal vez la tarea mÃ¡s emblemÃ¡tica de la RecuperaciÃ³n de InformaciÃ³n es la bÃºsqueda de _texto completo_.\n",
    "El problema consiste en dado un corpus grande de documentos, preprocesarlo para crear una estructura de bÃºsqueda que permita resolver consultas de manera eficiente. Una consulta es un texto corto que especÃ­fica lo que se desea encontrar en la colecciÃ³n. En particular, es un ejemplo de lo que se desea. Esto lleva a que la estructura de bÃºsqueda resuelve bÃºsquedas por similitud.\n",
    "\n",
    "La similitud, es entonces un tema central, pero para medirla lo primero es tener una representaciÃ³n de los datos que capture las propiedades deseadas (que serÃ¡n despuÃ©s evaluadas para medir la similitud). La manera mÃ¡s tradicional de hacerlo, es el uso de un modelo basado en bolsa de palabras (BOW). En dicho modelo, el texto es preprocesado, toquenizado y vectorizado.\n",
    "\n",
    "- El preprocesamiento incluye tratamientos tan simples como eliminar sÃ­mbolos no deseados, eliminiaciÃ³n de variantes lÃ©xicas, reducciÃ³n a raÃ­ces o lemas, correcciÃ³n de ortografÃ­a, eliminiaciÃ³n de palabras comunes (stop words). \n",
    "- El toquenizado es el proceso donde el texto es partido, en frases u oraciones, y finalmente en palabras y sÃ­mbolos que son unidades completas. En este punto tambiÃ©n es posible realizar normalizaciones, asÃ­ como tambiÃ©n realizar limpieza basada en estadÃ­sticas de los tÃ©rminos.\n",
    "- El vectorizado utiliza el vocabulario de una colecciÃ³n $\\{t_i\\}$ para generar una matriz de la colecciÃ³n, i.e., un vector por documento.\n",
    "\n",
    "Al proceso de modelar una colecciÃ³n mediante un vocabulario y luego ser capaces de generar una representaciÃ³n manejable por una computadora se le llama _modelo de lenguaje_.\n",
    "\n",
    "## Problema de bÃºsqueda\n",
    "Una vez que se genero el modelo de lenguaje y que fue usado para vectorizar una colecciÃ³n $X$, la idea es ser capaces de resolver consultas $Q$, i.e., encontrar un subconjunto de $X$ que mejor se apegue a una especificaciÃ³n $q \\in Q$. Las consultas deben ser codificadas de la misma forma, para generar un vector con ellas. Entonces el problema se transforma en encontrar los elementos mÃ¡s parecidos, que dada la representaciÃ³n, es conveniente usar el coseno entre vectores:\n",
    "\n",
    "$$ \\cos(u, q) = \\frac{ \\sum_i {u_i \\cdot q_i}}{\\sqrt{\\sum_i u_i^2} \\cdot \\sqrt{\\sum_i q_i^2}} $$\n",
    "\n",
    "AsÃ­ mismo, $d(u, q) = \\arccos(\\cos(u, q))$ serÃ­a el Ã¡ngulo entre ambos vectores, que ademÃ¡s es una mÃ©trica. El problema entonces se transforma en encontrar los vecinos mÃ¡s cercanos en la colecciÃ³n, esto es, si deseamos $k$ resultados de una consulta, estarÃ­amos deseando encontrar aquel subconjunto $knn$ de la colecciÃ³n tal que $\\sum_{v \\in knn} d(v, q)$ sea mÃ­nimo comparado con todo subconjunto de tamaÃ±o $k$ de la colecciÃ³n de documentos.\n",
    "\n",
    "## Velocidad de consultas\n",
    "Para mejorar la soluciÃ³n de consultas, es posible crear una estructura de datos que simplifique el proceso de encontrar el subconjunto $knn$. En este problema, con una representaciÃ³n basada en bolsa de palabras, la estructura mÃ¡s adecuada es el _Ã­ndice invertido.\n",
    "\n",
    "\n",
    "# Ãndice invertido\n",
    "\n",
    "Un Ã­ndice invertido es una representaciÃ³n dispersa de la matriz $W_{m,n}$ formada por $m$ componentes y $n$ documentos, i.e., cada celda $w_{t,i}$ es el peso asignado para el tÃ©rmino $t$ que ocurre en el documento $i$. Por construcciÃ³n, esta matriz tiene una gran cantidad de ceros, por lo que $W$ es altamente dispersa (pocos tÃ©rminos ocurren en un documento).\n",
    "\n",
    "$$ W \\left \\{\n",
    "\\begin{array}{rrrr rrrr rr}\n",
    "                & \\vec x_1& \\vec x_2&       & \\vec x_n \\\\\n",
    "t_1 \\rightarrow & w_{1,1} & w_{1,2} & \\dots & w_{1,n} \\\\\n",
    "t_2 \\rightarrow & w_{2,1} & w_{2,2} &       & w_{2,n} \\\\\n",
    "                & \\vdots  &         & \\ddots&         \\\\\n",
    "t_m \\rightarrow & w_{m,1} & w_{m,2} &       & w_{m,n} \\\\\n",
    "\\end{array}\n",
    "\\right .\n",
    "$$\n",
    "\n",
    "La representaciÃ³n es entonces por fila, a manera de lista de adjacencia; esto es, cada fila $t$ es representada por las tuplas $(i, w_{t,i})$, esto es, un Ã­ndice invertido es la siguiente estructura $W^*$\n",
    "\n",
    "$$ W^* \\left \\{\n",
    "\\begin{array}{rrr}\n",
    "t_1 & \\rightarrow & \\{(i, w_{1, i})\\} \\\\\n",
    "t_2 & \\rightarrow & \\{(i, w_{2, i})\\} \\\\\n",
    "\\vdots & \\vdots   &  \\hfill \\vdots \\hfill \\\\\n",
    "t_m & \\rightarrow & \\{(i, w_{m, i})\\} \\\\\n",
    "\\end{array}\n",
    "\\right .\n",
    "$$\n",
    "\n",
    "la tupla es usada siempre y cuando $w > 0$. Las tuplas suelen ordenarse por su identificador de columna, pero tambiÃ©n puede usarse el peso segÃºn convenga. A las filas suele llamarseles listas de posteo (_posting lists_). Los requerimientos de una matriz densa son altÃ­simos para representaciones de texto de alta dimensiÃ³n, representar las matrices de manera dispersa simplifica el manejo de la memorÃ­a, y como se verÃ¡ a continuaciÃ³n, tambiÃ©n influye enormemente en los tiempos de procesamiento.\n",
    "\n",
    "### BÃºsqueda mediante un Ã­ndice invertido\n",
    "\n",
    "La soluciÃ³n na\\\"ive de una obtener los $k$ documentos mÃ¡s similares es evaluar todos los vectores $\\vec{x}_i$, i.e., columnas de $W$, y determinar aquellos mÃ¡s similares, i.e., minimizar $d(\\vec{x}_i, q)$.\n",
    "\n",
    "El Ã­ndice invertido $W^*$ contiene la informaciÃ³n necesaria para realizar esta operaciÃ³n de manera eficiente. Primeramente, es necesario analizar la expresiÃ³n de $\\cos$. El denominador $\\sqrt{\\sum_i u_i^2} \\cdot \\sqrt{\\sum_i q_i^2}$, en sus partes es estÃ¡tico para cada vector, por lo que se puede preprocesar y no calcular de manera explÃ­cita para cada evaluaciÃ³n de $\\cos$. Con respecto al numerador corresponde al producto punto entre $\\vec{u}$ y $\\vec{q}$, $\\sum_i u_i \\cdot q_i$. Dicho esto, solo es necesario calcular los productos diferentes de cero; asÃ­ pues, la evaluaciÃ³n eficiente de $\\cos$ corresponde con una evaluaciÃ³n eficiente de la intersecciÃ³n de las componentes diferentes de cero. Los algoritmos como SvS, BY o BK, pueden ser de gran ayuda para este cÃ¡lculo. Note que aunque que los pesos con valor cero no se representan en $W^*$, dicho Ã­ndice representa informaciÃ³n por fila, lo cual no permite hacer operaciones eficientes entre $q$ y los vectores columna $\\vec x$ individuales.\n",
    "\n",
    "\n",
    "Afortunadamente, la evaluaciÃ³n se puede hacer eficiente para todo el conjunto de posibles candidatos (aquellos donde el producto punto contra $q$ sea diferente de cero). Para esto, se toman las componentes diferentes de cero en $q$, se toman las listas de adyacencia de $W^*$ y se procede a unirlas de manera eficiente. El conjunto de identificadores de documento resultado de esta uniÃ³n serÃ¡ aquel que debe ser evaluado para obtener el conjunto de documentos similares. \n",
    "Si uno toma la intersecciÃ³n, que puede ser mÃ¡s veloz de calcular, entonces podrÃ­an perderse documentos relavantes; es posible tambiÃ©n mandar el problema a un punto intermedio, es decir al problema de $t$-thresholds, donde se recupera un conjunto donde cada uno de los miembros aparece en al menos $t$ listas.\n",
    "La manera mÃ¡s eficiente, sin embargo, es realizar optimizaciones por filtrado de pesos o mejorando los esquemas de pesado; la idea general entonces es desaparecer entradas de $W*$ de tal forma que la uniÃ³n sea siempre pequeÃ±a. La adecuada optimizaciÃ³n de un Ã­ndice invertido puede hacerlo escalable a niveles realmente impresionantes.\n",
    "\n",
    "Los algoritmos de BK pueden ser utilizados para calcular la uniÃ³n y t-threasholds, asÃ­ como los algoritmos de mezcla clÃ¡sicos (_merge_). Es posible unir la operaciÃ³n de uniÃ³n con la operaciÃ³n de producto punto por vector usando los algoritmos adecuados.\n",
    "\n",
    "- <https://github.com/sadit/InvertedFiles.jl/blob/main/src/invfilesearch.jl>\n",
    "- <https://github.com/sadit/InvertedFiles.jl/blob/main/src/winvfilesearch.jl>\n",
    "- <https://github.com/sadit/Intersections.jl/blob/main/src/merge.jl>\n",
    "\n",
    "# Ejemplo\n",
    "\n",
    "El siguiente es un ejemplo de como cambia el desempeÃ±o usando una evaluaciÃ³n exhaustiva, un Ã­ndice invertido y una pequeÃ±a optimizaciÃ³n basada en modificaciÃ³n de pesos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb11ca12-b635-45bb-ac02-14523674ded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/IR-2022/Unidades`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "\n",
    "!isfile(\"Manifest.toml\") && Pkg.add([\n",
    "    PackageSpec(name=\"SimilaritySearch\", version=\"0.9\"),\n",
    "    PackageSpec(name=\"TextSearch\", version=\"0.12\"),\n",
    "    PackageSpec(name=\"InvertedFiles\", version=\"0.4\"),\n",
    "    PackageSpec(name=\"CodecZlib\", version=\"0.7\"),\n",
    "    PackageSpec(name=\"JSON\", version=\"0.21\"),\n",
    "    PackageSpec(name=\"HypertextLiteral\", version=\"0.9\")\n",
    "])\n",
    "\n",
    "using TextSearch, InvertedFiles, SimilaritySearch, TextSearch, CodecZlib, JSON, LinearAlgebra, HypertextLiteral\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd994e-6be8-45c8-a0fc-8f05dfcf2636",
   "metadata": {},
   "source": [
    "## Funciones para leer y modelar el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9482f05-8d88-4896-9b9e-646bc1da2abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_dataset (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function parse_corpus(corpusfile)\n",
    "    corpus, labels = String[], String[]\n",
    "    open(corpusfile) do f\n",
    "        for line in eachline(GzipDecompressorStream(f))\n",
    "            r = JSON.parse(line)\n",
    "            push!(labels, r[\"klass\"])\n",
    "            push!(corpus, r[\"text\"])    \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    corpus, labels\n",
    "end\n",
    "\n",
    "function text_model_and_vectors(\n",
    "        corpus;\n",
    "        textconfig=TextConfig(group_usr=true, group_url=true, del_diac=true, lc=true, group_num=true, nlist=[1], qlist=[]),\n",
    "        model=VectorModel(IdfWeighting(), TfWeighting(), textconfig, corpus)\n",
    "    )\n",
    "    vectors = vectorize_corpus(model, textconfig, corpus)\n",
    "    for v in vectors\n",
    "        normalize!(v)\n",
    "    end\n",
    "\n",
    "    (; textconfig, model, vectors)\n",
    "end\n",
    "\n",
    "function create_dataset(corpusfile)\n",
    "    corpus, labels = parse_corpus(corpusfile)\n",
    "    (; labels, corpus, text_model_and_vectors(corpus)...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1176ef00-1153-4cba-bb89-354d634c857e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Cargando el corpus (descargado en U1.ipynb)</h1>"
      ],
      "text/plain": [
       "<h1>Cargando el corpus (descargado en U1.ipynb)</h1>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(unique(D.labels), D.model) = ([\"ğŸ˜°\", \"ğŸ˜¥\", \"ğŸ˜Š\", \"ğŸ˜\", \"â™¡\", \"ğŸ’”\", \"ğŸ™‚\", \"ğŸ˜‹\", \"ğŸ˜Œ\", \"ğŸŒš\", \"ğŸ‘Œ\", \"ğŸ˜ª\", \"ğŸ˜¤\", \"ğŸ™ƒ\", \"ğŸ¤¤\", \"ğŸ˜´\", \"ğŸ˜¢\", \"ğŸ˜…\", \"ğŸ˜‘\", \"ğŸ˜ \", \"ğŸ˜‚\", \"ğŸ˜œ\", \"ğŸ¤“\", \"ğŸ’™\", \"ğŸ˜€\", \"ğŸ¤—\", \"ğŸ¤£\", \"ğŸ˜’\", \"âœ¨\", \"ğŸ˜\", \"ğŸ˜\", \"ğŸ˜\", \"ğŸ˜±\", \"ğŸ‘\", \"ğŸ˜«\", \"ğŸ˜\", \"â¤\", \"ğŸ˜£\", \"ğŸ™Š\", \"ğŸ™\", \"ğŸ™„\", \"ğŸ¤­\", \"ğŸ’œ\", \"ğŸ¤”\", \"ğŸ˜¬\", \"ğŸ‘€\", \"ğŸ˜‰\", \"ğŸ˜ˆ\", \"ğŸ˜¡\", \"ğŸ˜³\", \"ğŸ™ˆ\", \"ğŸ˜»\", \"ğŸ˜”\", \"ğŸ˜“\", \"ğŸ’•\", \"ğŸ¶\", \"ğŸ˜­\", \"ğŸ˜•\", \"â™¥\", \"ğŸ’–\", \"ğŸ˜\", \"ğŸ˜˜\", \"ğŸ˜ƒ\", \"ğŸ˜©\"], {VectorModel global_weighting=IdfWeighting(), local_weighting=TfWeighting(), train-voc=45374, train-n=50000, maxoccs=93991})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([\"ğŸ˜°\", \"ğŸ˜¥\", \"ğŸ˜Š\", \"ğŸ˜\", \"â™¡\", \"ğŸ’”\", \"ğŸ™‚\", \"ğŸ˜‹\", \"ğŸ˜Œ\", \"ğŸŒš\"  â€¦  \"ğŸ’•\", \"ğŸ¶\", \"ğŸ˜­\", \"ğŸ˜•\", \"â™¥\", \"ğŸ’–\", \"ğŸ˜\", \"ğŸ˜˜\", \"ğŸ˜ƒ\", \"ğŸ˜©\"], {VectorModel global_weighting=IdfWeighting(), local_weighting=TfWeighting(), train-voc=45374, train-n=50000, maxoccs=93991})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(@htl \"<h1>Cargando el corpus (descargado en U1.ipynb)</h1>\")\n",
    "dbfile = \"../data/emo50k.json.gz\"\n",
    "D = create_dataset(dbfile)\n",
    "@show unique(D.labels), D.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8671092-ee09-4370-b732-4d40d3d4b7b1",
   "metadata": {},
   "source": [
    "# Creando los diferentes mÃ©todos de bÃºsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7ccd91-c1c2-4a04-b792-d38a8c65342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{WeightedInvertedFile vocsize=3968, n=50000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ã­ndice invertido\n",
    "invfile = WeightedInvertedFile(length(D.model.voc))\n",
    "append!(invfile, VectorDatabase(D.vectors))\n",
    "\n",
    "## indice invertido con filtros al vocabulario\n",
    "fmodel = filter_tokens(D.model) do t\n",
    "    10 <= t.ndocs <= 1000  # filtrando los tokens que ocurren en entre 10 y 1000 documentos\n",
    "end\n",
    "\n",
    "## usando el modelo reducido de tokens\n",
    "fD = text_model_and_vectors(D.corpus, textconfig=D.textconfig, model=fmodel)\n",
    "\n",
    "finvfile = WeightedInvertedFile(length(fD.model.voc))\n",
    "append!(finvfile, VectorDatabase(fD.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d118cb7-f81d-4ad1-80fd-4a5245098ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The token filters can operate on any valid field of voc (passed as the named tuple <em>t</em>)"
      ],
      "text/plain": [
       "The token filters can operate on any valid field of voc (passed as the named tuple <em>t</em>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary <: Any\n",
      "  token::Vector{String}\n",
      "  occs::Vector{Int32}\n",
      "  ndocs::Vector{Int32}\n",
      "  weight::Vector{Float32}\n",
      "  token2id::Dict{String, UInt32}\n",
      "  corpuslen::Int64\n"
     ]
    }
   ],
   "source": [
    "display(@htl \"The token filters can operate on any valid field of voc (passed as the named tuple <em>t</em>)\")\n",
    "\n",
    "dump(typeof(D.model.voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046760fa-03d2-4bc9-a6cd-418c4f655b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorDatabase{Vector{Dict{UInt32, Float32}}}(Dict{UInt32, Float32}[Dict(0x00000054 => 0.3347092, 0x0000068a => 0.6846173, 0x00000044 => 0.34018824, 0x00000419 => 0.5509455), Dict(0x00000186 => 0.7395449, 0x000000a2 => 0.6731072), Dict(0x000000b0 => 0.23381734, 0x00000053 => 0.3259642, 0x000000e7 => 0.3169817, 0x0000001b => 0.2925202, 0x00000d35 => 0.49764267, 0x000001f5 => 0.34775817, 0x00000cb9 => 0.42758507, 0x000000e8 => 0.3187763), Dict(0x000000b0 => 0.3558882, 0x00000eef => 0.74962527, 0x000002e8 => 0.5580372), Dict(0x0000016b => 0.2604656, 0x0000004f => 0.23028766, 0x00000448 => 0.4283243, 0x000000c9 => 0.26923087, 0x000003eb => 0.44006115, 0x00000365 => 0.3291022, 0x000007af => 0.42488283, 0x00000a58 => 0.37508774), Dict(0x00000259 => 0.39137, 0x00000dd7 => 0.7243029, 0x000000bb => 0.5676397), Dict(0x00000084 => 0.4996388, 0x00000d45 => 0.8662338), Dict(0x00000487 => 0.22856358, 0x00000bf3 => 0.2630118, 0x000006a7 => 0.23114121, 0x00000293 => 0.2616991, 0x00000916 => 0.25267273, 0x00000b2c => 0.27989882, 0x000000a6 => 0.17348991, 0x00000817 => 0.25578964, 0x000009e4 => 0.23695171, 0x00000054 => 0.13684246â€¦), Dict(0x000000a9 => 0.36354518, 0x00000a07 => 0.5120805, 0x000002bd => 0.45747685, 0x0000017e => 0.5208684, 0x0000017d => 0.35358092), Dict(0x0000038c => 0.52716184, 0x00000157 => 0.32211804, 0x0000046a => 0.4700343, 0x00000076 => 0.32827374, 0x0000024d => 0.3729686, 0x00000103 => 0.3879934)  â€¦  Dict(0x00000037 => 0.5387884, 0x00000166 => 0.67586136, 0x000000b6 => 0.50291), Dict(0x00000a97 => 0.56313527, 0x0000003c => 0.3634544, 0x00000102 => 0.31194425, 0x00000738 => 0.5609515, 0x00000294 => 0.3725638), Dict(0x000001f9 => 0.6903055, 0x000004b0 => 0.723518), Dict(0x000000b6 => 0.4383699, 0x00000060 => 0.89879465), Dict(0x00000341 => 0.38676968, 0x00000a46 => 0.42377207, 0x000006a3 => 0.4065749, 0x000002d3 => 0.2684107, 0x000000f8 => 0.26224124, 0x00000077 => 0.3272776, 0x0000066e => 0.34812984, 0x00000bbc => 0.36932853), Dict(0x00000037 => 0.26218536, 0x00000463 => 0.40796354, 0x000001ad => 0.2909695, 0x000000d8 => 0.36215267, 0x000009b1 => 0.42634773, 0x000002d5 => 0.3597346, 0x000009b0 => 0.41706774, 0x00000059 => 0.25274485), Dict(0x0000040b => 0.33927795, 0x00000cb9 => 0.5557221, 0x000006a0 => 0.54573447, 0x000001c6 => 0.52748203), Dict(0x0000014d => 0.36407647, 0x0000082e => 0.5690961, 0x000000fe => 0.35886785, 0x00000789 => 0.5174932, 0x000002cc => 0.3833961), Dict(0x0000032f => 0.4749454, 0x00000bec => 0.61925524, 0x00000bed => 0.6252598), Dict(0x0000000d => 0.19462189, 0x00000353 => 0.3761832, 0x00000b66 => 0.36356863, 0x00000cae => 0.3654544, 0x00000c61 => 0.40492746, 0x000000f9 => 0.32582772, 0x00000857 => 0.34660488, 0x000009e6 => 0.34927666, 0x00000017 => 0.20642276)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = VectorDatabase(rand(D.vectors, 1000))\n",
    "fQ = VectorDatabase(rand(fD.vectors, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0f207f2-ed09-4fec-9da6-2ad625c21801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.292747 seconds (1.93 M allocations: 141.872 MiB, 3.65% gc time, 65.59% compilation time)\n",
      "  0.491890 seconds (648.26 k allocations: 34.584 MiB, 67.35% compilation time)\n",
      "  0.239561 seconds (21 allocations: 125.688 KiB)\n",
      "  0.003348 seconds (6 allocations: 125.250 KiB)\n"
     ]
    }
   ],
   "source": [
    "# evaluaciÃ³n exhaustiva\n",
    "brute = ExhaustiveSearch(; db=D.vectors, dist=NormalizedCosineDistance())\n",
    "fbrute = ExhaustiveSearch(; db=fD.vectors, dist=NormalizedCosineDistance())\n",
    "\n",
    "@time searchbatch(brute, Q, 16)\n",
    "@time searchbatch(invfile, Q, 16)\n",
    "@time searchbatch(fbrute, fQ, 16)\n",
    "@time searchbatch(finvfile, fQ, 16)\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad823b-70c0-447d-bfe0-8a920525ca12",
   "metadata": {},
   "source": [
    "## Se volverÃ¡ a realizar la operaciÃ³n pero con unas pequeÃ±as modificaciones para remover el costo de compilaciÃ³n y el costo de recolecciÃ³n de basura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde30ad5-8c2d-4622-b0c2-994802b64e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.164695 seconds (2.69 k allocations: 280.063 KiB, 7.34% compilation time)\n",
      "  0.484623 seconds (70 allocations: 127.219 KiB)\n",
      "  0.003244 seconds (8 allocations: 125.312 KiB)\n",
      "  0.238250 seconds (22 allocations: 125.719 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC.enable(false)\n",
    "@time I, _ = searchbatch(invfile, Q, 16)\n",
    "@time G, _ = searchbatch(brute, Q, 16)\n",
    "@time fI, _ = searchbatch(finvfile, fQ, 16)\n",
    "@time fG, _= searchbatch(fbrute, fQ, 16)\n",
    "GC.enable(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc566c35-ebb2-4725-a524-a0737319db22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macrorecall(G, I) = 0.9975\n",
      "macrorecall(fG, fI) = 0.9498125\n",
      "macrorecall(G, fG) = 0.001\n",
      "macrorecall(G, fI) = 0.0009375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0009375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### La diferencia de costos puede ser importante, por lo que es tambiÃ©n necesario saber el impacto con respecto a la calidad perdida\n",
    "@show macrorecall(G, I)\n",
    "@show macrorecall(fG, fI)\n",
    "@show macrorecall(G, fG)\n",
    "@show macrorecall(G, fI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f23a7-1e9c-4091-a63c-84695e325598",
   "metadata": {},
   "source": [
    "# Sobre los resultados\n",
    "Afortunadamente no es tan simple como decir que se destruyo la calidad del resultado,\n",
    "ya que eso implicarÃ­a que el modelo sin filtros fuera mejor y eso no es necesariamente\n",
    "cierto ya que los filtros podrÃ­an estar removiendo tÃ©rminos _ruidosos_ (errores ortogrÃ¡ficos y palabras que al ser tan comunes aportan poco al resultado).\n",
    "Lo que sÃ­ se puede afirmar es que los dos conjuntos de resultados son diferentes y esto es importante de tener\n",
    "en cuenta cuando se realizan modificaciones a los modelos.\n",
    "\n",
    "Tradicionalmente, los resultados se miden con el recall, pero el _gold standard_ es construido a partir de\n",
    "intervenciÃ³n humana, que es capaz de decir que documentos son relevantes a una consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5be69f7-5458-4e1c-b0fa-a14ab2600986",
   "metadata": {},
   "source": [
    "# Actividades\n",
    "\n",
    "- Â¿QuÃ© es el recall?\n",
    "- Â¿QuÃ© es macro-recall?\n",
    "- Explique el porque de las mejoras en tiempo. Use anÃ¡lisis de algoritmos para este ejercicio.\n",
    "- Implemente un Ã­ndice invertido que sea capaz de mejorar los tiempos de bÃºsqueda tal y como se muestra en este ejercicio. Para el procesamiento del texto y toquenizado use librerias/paquetes externos.\n",
    "- Reporte mediante un notebook de Jupyter su implementaciÃ³n, use uno de los conjuntos de datos para ejemplificar su uso y medir los desempeÃ±os."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
